# =============================================================================
# BLIP Image Captioning Configuration
# =============================================================================
# Author: Tharun Ponnam
# =============================================================================

model:
  name: "blip-image-captioning"
  pretrained: "Salesforce/blip-image-captioning-large"
  device: "auto"
  
  vision_encoder:
    model_name: "vit-large-patch16"
    image_size: 384
    patch_size: 16
    hidden_size: 1024
    num_layers: 24
    num_heads: 16
    
  text_decoder:
    max_length: 50
    min_length: 5
    vocab_size: 30522
    hidden_size: 768
    num_layers: 12
    num_heads: 12

generation:
  strategy: "beam_search"
  num_beams: 5
  max_length: 50
  min_length: 5
  repetition_penalty: 1.5
  length_penalty: 1.0
  early_stopping: true

preprocessing:
  image_size: 384
  mean: [0.48145466, 0.4578275, 0.40821073]
  std: [0.26862954, 0.26130258, 0.27577711]
  
evaluation:
  metrics:
    - bleu
    - cider
    - meteor
    - spice
  batch_size: 32

streamlit:
  theme: "light"
  page_title: "BLIP Image Captioning"
  page_icon: "üñºÔ∏è"
  layout: "centered"

logging:
  level: "INFO"

seed: 42
